---
title: "Visual Detective Assignment Part 2"
description: |
  This assignment attempts to solve the 2021 IEEE Visual Analytics Science and Technology (VAST) Challenge: Mini-Challenge 2 by applying different visual analytics concepts, methods, and techniques with relevant R data visualisation and data analysis packages.

preview: img/preview_image.png  
author:
  - name: Archie Dolit
    url: https://www.linkedin.com/in/adolit/
    affiliation: School of Computing and Information Systems, Singapore Management University
date: 07-25-2021
output:
  distill::distill_article:
    self_contained: false
    toc: true
    toc_depth: 3
categories:
  - Visual Detective
  - R
  - Assignment
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(fig.retina=3,
                      echo = TRUE,
                      eval = TRUE,
                      message = FALSE,
                      warning = FALSE)
```

```{r r package, echo = FALSE}
packages = c('ggiraph', 'plotly','lobstr',
             'raster','sf', 'tmap', 
             'igraph', 'tidygraph', 
             'ggraph', 'visNetwork', 
             'lubridate', 'clock',
             'widyr', 'wordcloud',
             'ggwordcloud', 'DT',
             'textplot', 'hms',
             'timetk','tidyverse')

for(p in packages){
  if(!require(p, character.only = T)){
    install.packages(p)
  }
  library(p, character.only = T)
}
```

```{r import csv, echo = FALSE}
car_data <- read_csv("data/aspatial/car-assignments.csv")
cc_data <- read_csv("data/aspatial/cc_data.csv")
loyalty_data <- read_csv("data/aspatial/loyalty_data.csv")
gps_data <- read_csv("data/aspatial/gps.csv")
```

```{r bgmap, echo = FALSE}
bgmap <- raster("data/Geospatial/abila_map.tif")
# 
# tm_shape(bgmap) +
# tm_rgb(bgmap, r = 1,g = 2,b = 3,
#        alpha = NA,
#        saturation = 1,
#        interpolate = TRUE,
#        max.value = 255)
```

```{r prep car, echo = FALSE}
car_data <- car_data %>%
  #concatenate first and last name
  mutate(FullName = paste(FirstName, LastName, sep = " ")) %>%
  rename(Deparment = CurrentEmploymentType) %>%
  rename(Title = CurrentEmploymentTitle)

car_data$CarID <- as_factor(car_data$CarID)
```

```{r prep cc, echo = FALSE}

#detect and replace Katerina to Katerina's Cafe
cc_data <- cc_data %>%
    mutate(location = ifelse(str_detect(location, "Katerina"), "Katerina's Cafe", location))

#convert to date-time format
cc_data$date <- date_time_parse(cc_data$timestamp,
                zone = "",
                format = "%m/%d/%Y")
cc_data$day <- wday(cc_data$date,
                          label = TRUE,
                          abbr = TRUE)

cc_data$timestamp <- date_time_parse(cc_data$timestamp,
                zone = "",
                format = "%m/%d/%Y %H:%M")

cc_data$hour <- get_hour(cc_data$timestamp)
```

```{r prep loyal, echo = FALSE}

#detect and replace Katerina to Katerina's Cafe
loyalty_data <- loyalty_data %>%
    mutate(location = ifelse(str_detect(location, "Katerina"), "Katerina's Cafe", location))

#convert to date-time format
loyalty_data$date <- date_time_parse(loyalty_data$timestamp,
                zone = "",
                format = "%m/%d/%Y")

loyalty_data$timestamp <- date_time_parse(loyalty_data$timestamp,
                zone = "",
                format = "%m/%d/%Y")

loyalty_data$day <- wday(loyalty_data$timestamp,
                          label = TRUE,
                          abbr = TRUE)
```

```{r prep gps, echo = FALSE}

#rename columns for consistency
gps_data <- gps_data %>%
  rename(timestamp = Timestamp) %>%
  rename(CarID = id)

#convert to date-time format
gps_data$date <- date_time_parse(gps_data$timestamp,
                zone = "",
                format = "%m/%d/%Y")

gps_data$day <- as.factor(wday(gps_data$date,
                          label = TRUE,
                          abbr = TRUE))

gps_data$timestamp <- date_time_parse(gps_data$timestamp,
                zone = "",
                format = "%m/%d/%Y %H:%M:%S")

gps_data$hour <- get_hour(gps_data$timestamp)

#convert to factor data type
gps_data$CarID <- as_factor(gps_data$CarID)

#convert to simple feature 
gps_sf <- st_as_sf(gps_data, 
                   coords = c("long", "lat"),
                       crs= 4326)
```

```{r join cc_loyal, echo = FALSE}

#combine based on date, location, price, exclude day and timestamp
cc_loyalty_data <- full_join(cc_data %>% select(-c("day")),
                             loyalty_data %>% select(-c("day","timestamp")), 
                             by = c("date" = "date", 
                                    "location" = "location", 
                                    "price" = "price"))

#get day of the joint data
cc_loyalty_data$day <- wday(cc_loyalty_data$date,
                          label = TRUE,
                          abbr = TRUE)

#rearrange columns
cc_loyalty_data <- cc_loyalty_data %>%
  select("timestamp", "date", "day", "hour", "location", "price", "last4ccnum", "loyaltynum")
```

```{r join car_gps, echo = FALSE}

#combine based on CarID
car_gps_data <- left_join(gps_data, 
                          car_data %>% select(-c("FirstName", "LastName")),
                          by = "CarID")

car_gps_sf <- left_join(gps_sf,
                        car_data %>% select(-c("FirstName", "LastName")),
                        by = "CarID")
```

# 4. Proposed Solutions

## Q1: Most Popular Locations

**Using just the credit and loyalty card data, identify the most popular locations, and when they are popular. What anomalies do you see? What corrections would you recommend to correct these anomalies?**

Generate an interactive bar graph in descending order using _ggplot_ and _plotly_ to determine the most popular locations.

```{r q1 popular, fig.height=8}
popular_combine <- cc_loyalty_data %>%
  group_by(location) %>%
  summarize(total_count=n()) %>%
  ggplot(aes(x=reorder(location, total_count),
             y=total_count,
             text = paste("Location :", location,"\n",
                          "Number of transactions:", total_count))) +
  geom_bar(stat="identity", fill = "royalblue4") +
  ggtitle("Combined Credit Card & Loyalty Transactions") +
  labs(x = "Locations", y = "Transaction Count") + 
  coord_flip() +
  theme_minimal()

ggplotly(popular_combine, tooltip = "text")
```
Based on the combined combined credit card and loyalty data, the most popular location is _Katerina's Cafe_ with a total of 256 transactions, followed by _Hippokampos_ with 213 transactions and _Guy's Gyro_ with 187 transactions.


Generate an interactive heatmap using _ggplot_ and _plotly_ to determine the date and time when employees visit the locations.

```{r q1 popular date, fig.height=8}
day_location_count <- cc_loyalty_data %>%
  count(location, day) %>%
  rename(count = n)

popular_day_location <- ggplot(data = day_location_count,
                               aes(x=day, y=reorder(location, desc(location)),
                                   fill = count,
                                   text = paste("Location :", location,"\n",
                                                "Day of week:", day,"\n",
                                                "Number of transactions :", count))) +
  geom_tile()+
  scale_fill_gradient(low = "lightsteelblue1", high = "royalblue4") +
  ggtitle("Combined Credit Card & Loyalty Transactions by Day") +
  labs(x = "Day of the Week",y = "Locations") + 
  theme_minimal()

ggplotly(popular_day_location, tooltip = "text")
```
Based on the combined combined credit card and loyalty data, _Brew've Been Served_ is popular on weekdays, Monday to Friday, with no transactions on weekend. Probably this location is only open weekday.

_Guy's Gyro, Hippokampos, and Katerina's Cafe_ are very popular throughout the week, Sunday to Monday.
_Katerina's Cafe_ is the most popular location on Saturday with a total of 42 transactions.

Some of the interesting transactions are _U-Pump_ with 2 transactions only on Monday and _Desafio Golf Course_ with only 9 transactions only on Sunday.


```{r q1 popular time, fig.height=8}
hour_location_count <- cc_loyalty_data %>%
  count(location, hour) %>%
  rename(count = n)
  
popular_hour_location <- ggplot(data = hour_location_count,
                               aes(x=hour, y=reorder(location, desc(location)),
                                   fill = count,
                                   text = paste("Location :", location,"\n",
                                                "Hour of the Day:", hour,"\n",
                                                "Number of transactions :", count))) +
  geom_tile()+
  scale_fill_gradient(low = "lightsteelblue1", high = "royalblue4") +
  ggtitle("Combined Credit Card & Loyalty Transactions by Hour of Day") +
  labs(x = "Hour of the Day",y = "Locations") + 
  theme_minimal()

ggplotly(popular_hour_location, tooltip = "text")
```

Based on the time of transaction, _Brew've Been Served and Hallowed Grounds_ are popular in the morning around 7AM and 8AM. Most probably the employees visit the place before heading to the office.


_Abila Zacharo, Bean There Done That, Brewed Awakenings, Gelatogalore, Guy's Gyro, Hippokampos, Jack's Magical Beans, Kalami Kafenion, Katerina's Kafe, and Ouzera Elian_ are popular during lunch break around 12NN to 1PM.

_Guy's Gyro, Hippokampos, and  Katerina's Kafe_ are popular during dinner around 7PM and 8PM.
_Katerina's Kafe_ has the highest transactions at 85 purchases at around 8PM.


Generate an interactive boxplot using _plotly_ to determine the outliers and provide clues on some anomalies.

```{r q1 outlier,  fig.height=8}
outlier <- plot_ly(data = cc_loyalty_data,
                   x = ~price,
                   color = I("royalblue4"),
                   alpha = 0.5,
                   boxpoints = "suspectedoutliers") %>%
  add_boxplot(y = ~reorder(location, desc(location))) %>%
  layout(title = "Combined Credit Card & Loyalty Transactions Outliers",
         yaxis = list(title = "Locations"),
         xaxis = list(title = "Price"))

outlier
```

Based on the price of transaction, it seems that there is unusual expensive purchase at _Frydos Autosupply n More_ amount to *10,000*.
This is highly suspicious since the _mean price_ for this location is only *161.96* with third quartile value of approximately *250*.


Generate an interactive linegraph using _plot_anomaly_diagnostics()_ of _plotly_ to diagnose anomalous points in the _cc_data_ purchase prices.
Note that only locations with sufficient number of observations were selected for the anomaly diagnostics.

```{r q1 anomaly,  fig.height=8}

cc_data %>%
  filter(location %in% c("Abila Airport",
                         "Albert's Fine Clothing",
                         "Carlyle Chemical Inc.",
                         "Chostus Hotel",
                         "Frydos Autosupply n' More",
                         "Gelatogalore",
                         "Nationwide Refinery",
                         "Stewart and Sons Fabrication")) %>%
  group_by(location) %>%
  plot_anomaly_diagnostics(timestamp, price, 
                           .facet_ncol = 2,
                           .y_lab = "Price")
```
Based on the anomaly diagnostics, there are unusual purchases in _Gelatogalore, Frydos Autosupply n' More, Albert's Fine Clothing, and Chostus Hotel_.
Again, the most expensive purchase is from _Frydos Autosupply n More_ amounting to **10,000 on 2014-01-13 19:20:00**.

The anomalies will not be removed or corrected. It will be kept in the data since it may lead to more clues in solving the challenge.


## Q2: Anomalies in Vehicle, Credit Card and Loyalty Card Data

**Add the vehicle data to your analysis of the credit and loyalty card data. How does your assessment of the anomalies in question 1 change based on this new data? What discrepancies between vehicle, credit, and loyalty card data do you find?**


Generate an interactive heatmap using _ggplot_ and _plotly_ based on the amount of transactions with missing _last4ccnum_.

```{r q2 missing last4ccnum, fig.height=8}

missing_last4ccnum <- cc_loyalty_data %>%
   filter(is.na(last4ccnum)) 

na_last4ccnum  <- ggplot(data = missing_last4ccnum,
                         aes(x=date, y=reorder(location, desc(location)),
                                   fill = price,
                                   text = paste("Location :", location,"\n",
                                                "Date:", date,"\n",
                                                "Total Amount of Transaction:", price))) +
  geom_tile()+
  scale_fill_gradient(low = "lightsteelblue1", high = "royalblue4") +
  ggtitle("Transactions with Missing Credit Card Data by Date") +
  labs(x = "Date of Transaction", y = "Locations") +
  theme_minimal()

ggplotly(na_last4ccnum, tooltip = "text")
```

Based on the total amount of transactions with missing credit card, _National Refinery_ has a transaction on _2014-01-08_ with a price of _4367.63_.
_Stewart and Sons Fabrication_ has a transaction on _2014-01-13_ with a price of _4071.95_ and another one on _2014-01-15_ with a price of _4485.38_.

The discrepancies may be due to employees who bought the items with cash instead of credit card but still used the loyalty card to redeem points or rewards.


Generate another interactive heatmap using _ggplot_ and _plotly_ based on the amount of transactions with missing _loyaltynum_.

```{r q2 missing loyaltynum, fig.height=8}

missing_loyaltynum <- cc_loyalty_data %>%
   filter(is.na(loyaltynum))

na_loyaltynum  <- ggplot(data = missing_loyaltynum,
                         aes(x=date, y=reorder(location, desc(location)),
                                   fill = price,
                                   text = paste("Location :", location,"\n",
                                                "Date:", timestamp,"\n",
                                                "Total Amount of Transaction:", price))) +
  geom_tile()+
  scale_fill_gradient(low = "lightsteelblue1", high = "royalblue4") +
  ggtitle("Transactions with Missing Loyalty Data by Date") +
  labs(x = "Date of Transaction", y = "Locations") +
  theme_minimal()

ggplotly(na_loyaltynum, tooltip = "text")
```

Based on the total amount of transactions with missing loyalty card, _Frydos Autosupply n More_ has a transaction on _2014-01-13 19:20:00_ with a price of _10,000_.

The discrepancy is more suspicious since the person who bought the items did not use his loyalty card which may imply possible misuse of the credit card when making the transaction.


Add the gps and car data by creating a movement path from GPS points using the CarIDs as unique identifier.
Filter the data around the time of transaction from _2014-01-13 19:00 to 21:00_.

```{r q2 gps path 0113}
gps_path_0113 <- car_gps_sf %>%
  filter(timestamp >= "2014-01-13 19:00" & timestamp <= "2014-01-13 21:00") %>%
  group_by(CarID, date) %>%
  summarize(m = mean(timestamp), 
            do_union=FALSE) %>%
  st_cast("LINESTRING") 
```


Plot the gps path on the background tourist map and identity which CarIDs are within the vicinity of _Frydos Autosupply n More_.

```{r q2 gps path 0113 1900}
gps_path_selected_0113 <- gps_path_0113 %>%
  filter(CarID %in% c("13" , "15", "16", "34"))

tmap_mode("view")
tm_shape(bgmap) +
  tm_rgb(bgmap, r = 1,g = 2,b = 3,
       alpha = NA,
       saturation = 1,
       interpolate = TRUE,
       max.value = 255) +
  tm_shape(gps_path_selected_0113) +
  tm_lines() +
  tm_facets(by = "CarID",  ncol = 1)
```

From the gps paths, CarID _"13" , "15", "16", "34"_ are within the vicinity of _Frydos Autosupply n More_ during suspicions transaction amounting to the price of _10,000_.


Create an interactive data table based on the joint gps and car and filter the date to _2014-01-13_.

```{r q2 gps table}
car_gps_0113 <- car_gps_data %>%
  filter(timestamp >= "2014-01-13 19:00" & timestamp <= "2014-01-13 21:00") %>%
  filter(CarID %in% c("13" , "15", "16", "34")) %>%
  group_by(CarID, Deparment, Title, FullName) %>%
  summarise()

DT::datatable(car_gps_0113)
```
From the interactive table, all CarIDs identified are from the Security Department. 
Possibly, _Isia Vann_ and _Edvard Vann_ are relatives because of the same Last Name and working together as Perimeter Controller.


## Q3: Owners of Credit Card and Loyalty Card


**Can you infer the owners of each credit card and loyalty card? What is your evidence? Where are there uncertainties in your method? Where are there uncertainties in the data?**

It is challenging to infer the owners of the credit card and loyalty card since there is no data field to join the credit card and gps data. 

One possible approach to plot the gps path and check it against timestamp of the credit card transactions. 
This approach assumes that the person driving the car is the same person making the credit card transaction.
Additionally, it assumes that the gps coordinates, timestamp as well as the credit location and timestamp are accurate.

To implement this proposed approach, it assumes the geospatial tracking software installed in the employees car will stop tracking if the vehicle is not moving.
Borrowing from concept of 'Point of Interest' (POI) from Virginia Tech, POI is identified if the employee stops for more than 5 minutes.


Identify the POIs by computing the difference of gps timestamp. If the difference is greater than 5 minutes, it will be set to poi = TRUE.

```{r q3 poi}
gps_poi_sf <- car_gps_sf %>%
  group_by(CarID) %>%
  mutate(diff = timestamp - lag(timestamp, order_by=CarID)) %>%
  mutate(poi = if_else(diff > 60*5,  TRUE, FALSE)) %>%
  filter(poi == TRUE) %>%
  ungroup() 

glimpse(gps_poi_sf)
```


Plot the POIs on the backgroup tourist map and identity the employee locations.
From the  _Combined Credit Card & Loyalty Transactions by Hour of Day_ heatmap of Question 1, the earliest transaction is around 3:00 AM from Kronos Mart while the last transaction is 10:00 PM from Hippokampos. This information can be used to limit the number of POIs.


```{r q3 poi points}
gps_poi_points <- gps_poi_sf %>%
  filter(hour >= 3 & hour <= 23) %>%
  select(timestamp,
         CarID,
         Deparment,
         Title,
         FullName)

tmap_mode("view")
tm_shape(bgmap) +
  tm_rgb(bgmap, r = 1,g = 2,b = 3,
       alpha = NA,
       saturation = 1,
       interpolate = TRUE,
       max.value = 255) +
  tm_shape(gps_poi_points) +
  tm_dots(col = 'red', border.col = 'black', size = 1, alpha = 0.5, jitter = .8) +
  tm_facets(by = "FullName", ncol = 1)
```


Create an interative data table based on the joint credit card and infer the owner based on the POI plot.

```{r q3 table cc data}

cc_owner <- cc_data %>%
  select(timestamp, location, last4ccnum)

DT::datatable(cc_owner)
```

Finally, manually map the credit card transaction purchases timestamp against the POI map. This approach is very time consuming since it entails manual effort.
As for most cases, the POI map may show certain points around the vicinity of the location but does not have any corresponding credit card purchases.


The owner of the loyalty card will be known after the credit card owner has been identified. 
As noted earlier, there is no one-to-one correspondence between the credit and loyalty card. 

The heatmap below visualizes the number of transactions between specific credit card and loyalty card to know the highest likelihood of the loyalty card owner.

```{r count cc loyal,fig.height=8}
cc_loyal_count <- cc_loyalty_data %>%
  group_by(last4ccnum,loyaltynum) %>%
  summarise(count=n())
  
cc_loyal_correlate <- ggplot(data = cc_loyal_count,
                               aes(x=loyaltynum, y=as.factor(last4ccnum),
                                   fill = count,
                                   text = paste("Last 4 Credit Card Number :", last4ccnum,"\n",
                                                "Loyalty Card Number:", loyaltynum,"\n",
                                                "Number of transactions :", count))) +
  geom_tile()+
  scale_fill_gradient(low = "lightsteelblue1", high = "royalblue4") +
  ggtitle("Correlation of Credit Card & Loyalty Card by Number of Transactions") +
  labs(x = "Loyalty Card Number",y = "Credit Card Number") + 
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 90))

ggplotly(cc_loyal_correlate, tooltip = "text")
```

From the heatmap, it can seen that certain combination of credit card number and loyalty card are most often used together.
Example of which are _6901 and L9363_ with 28 transactions; _7117 and L6417_ also with 28 transactions.

Nevertheless, even for credit card 6901, there are still _9 transactions_ when loyalty card was not used.
Similarly, credit card 7117 has _3 transactions_ when loyalty card was not used.


## Q4: Relationships among GASTech Personnel

**Given the data sources provided, identify potential informal or unofficial relationships among GASTech personnel. Provide evidence for these relationships.**


Similar to question 3, identify the POIs by computing the difference of gps timestamp. 

Afterwards, identify who are within 'close contact' of each employee based on the difference of their gps coordinates within the same time period.

This can help establish the relationship of GASTech personnel according to their meetings at the same place and at the same time.


```{r q4 poi network}
gps_poi_network <- car_gps_data %>%
  group_by(CarID) %>%
  mutate(poi_diff = timestamp - lag(timestamp, order_by=CarID)) %>%
  mutate(poi = if_else(poi_diff > 60*5,  TRUE, FALSE)) %>%
  filter(poi == TRUE) %>%
  ungroup() %>%
  mutate(lat_diff = lat - lag(lat, order_by=timestamp))%>%
  mutate(long_diff = long - lag(long, order_by=timestamp)) %>%
  mutate(close_contact = if_else(abs(lat_diff) <=0.001 & abs(long_diff) <=0.001, TRUE, FALSE))%>%
  filter(close_contact == TRUE) %>%
  ungroup()
  
glimpse(gps_poi_network)
```


```{r q4 poi network diagram}

 employee_edges <- gps_poi_network %>%
  group_by(date, hour)%>%
  mutate(from = FullName) %>%
  mutate(to = lead(FullName, order_by = timestamp)) %>%
  ungroup() %>%
  group_by(from,to) %>%
  summarise(weight = n())

 employee_nodes <- gps_poi_network %>%
   select(FullName, Deparment, Title) %>%
   rename(id = FullName) %>%
   rename(group = Deparment) %>%
   distinct()
 
 visNetwork(employee_nodes,
            employee_edges,
            main = "Relationships among GASTech Personnel") %>%
   visIgraphLayout(layout = "layout_with_fr") %>%
   visEdges(arrows = "to", 
            smooth = list(enabled = TRUE, 
                          type = "curvedCW")) %>%
   visOptions(highlightNearest = TRUE,
             nodesIdSelection = TRUE) %>%
   visLegend() %>%
   visLayout(randomSeed = 123)
```

The network diagram shows the 'official' relationship of employees based on their respective departments. It also show 'unofficial' relationship based on the number of their interactions.

From the  network diagram, it can be seen that _Isande Barrasca_ , a Drill Technician from the Engineering Department is an outlier.
His only close contact to the rest of employees is _Hideki Cocinaro_ , a Site Controller from the Security Department.

Similarly, _Sten Sanjorge Jr._ , IT Technician from the Information Technology Department, have minimal interactions with other employees and seems not well connected within the company.


The heatmap below visualizes the number of interactions between employees.

```{r q4 employee interaction, fig.height=8}
employee_interact1 <- full_join(employee_edges, 
                             employee_nodes, 
                             by = (c("from" = "id"))) %>%
  rename(SenderDepartment = group) %>%
  rename(SenderTitle = Title)

employee_interact2 <- full_join(employee_interact1, 
                             employee_nodes, 
                             by = (c("to" = "id"))) %>%
  rename(ReceiverDepartment = group) %>%
  rename(ReceiverTitle = Title) %>%
  rename(Sender = from) %>%
  rename(Receiver = to)

employee_interaction  <- ggplot(data = employee_interact2,
                         aes(x=Sender, y=Receiver,
                                   fill = weight,
                                   text = paste("Sender :", Sender,"\n",
                                                "Sender Department:", SenderDepartment, "\n",
                                                "Sender Title:", SenderTitle, "\n",
                                                "\n",
                                                "Receiver", Receiver,"\n",
                                                "Receiver Department:", ReceiverDepartment, "\n",
                                                "Receiver Title:", ReceiverTitle, "\n",
                                                "\n",
                                                "Number of Meetings", weight))) +
  geom_tile()+
  scale_fill_gradient(low = "lightsteelblue1", high = "royalblue4") +
  ggtitle("GAStech Personnel Relationship based on number of Interactions") +
  labs(x = "Sender Employee", y = "Receiver Employee") +
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 90))
  
ggplotly(employee_interaction, tooltip = "text")
```

The highest number of meetings among GAStech Personnel are truck drivers with 23 interactions. Employee names are set to _NA_ since the CarID is not identified.
The second highest number of meetings is from _Bertrand Ovan_, Group Manager of Facilities department with 14 meetings.  
The third highest number of meetings is from _Ingrid Barranco_, SVP/CFO from Executive department with 12 meetings.


## Q5: Evidence of Suspicious Activities

**Do you see evidence of suspicious activity? Identify 1- 10 locations where you believe the suspicious activity is occurring, and why.**

Building on the POI network with employee interactions from Question 4, covert the gps coordinates to simple feature and plot it in the tourist map.

```{r q5 poi gps}

gps_poi_network_sf <- st_as_sf(gps_poi_network,
                               coords = c("long", "lat"),
                               crs= 4326)
gps_poi_network_sf
```

```{r q5 poi map}
gps_poi_network_points <- gps_poi_network_sf %>%
  select(timestamp,
         CarID,
         Deparment,
         Title,
         FullName,
         date,
         hour)

tmap_mode("view")
tm_shape(bgmap) +
  tm_rgb(bgmap, r = 1,g = 2,b = 3,
       alpha = NA,
       saturation = 1,
       interpolate = TRUE,
       max.value = 255) +
  tm_shape(gps_poi_network_points) +
  tm_dots(col = 'red', border.col = 'black', size = 1, alpha = 0.5, jitter = .8) +
  tm_facets(by = "date", ncol = 1)
```
**1. Frydos Autosupply n More**

This is the suspicious place because of the _10,000_ spent on _2014-01-13_.
Additionally, members of the Security department frequently visit this place:

![](img/q5_02_frydos.png){width=95%}
![](img/q5_02_frydos2.png){width=95%}

![](img/q5_02_frydos3.png){width=95%}
![](img/q5_02_frydos4.png){width=95%}



**2. Spetsons Park**

On _January 07, 2014, 3:25_, Isia Vann visited this place which is very unusual especially in the wee hours of the morning.

![](img/q5_01_spetson_park_2.png){width=95%}


**3. CEO's house**

On _January 10, 2014, 23:23_, Axel Calzas visited the place where the CEO is residing, he was followed by Kanon Herrero at arond _23:33_
After a few hours, Felix Balas can also be seen around the vicinity On _January 11, 2014, 00:25_.

Photo Evidences|   

![](img/q5_05_ceo_house.png){width=95%}
![](img/q5_05_ceo_house3.png){width=95%}

![](img/q5_05_ceo_house2.png){width=95%}


**4. Chostus Hotel**

On _January 08, 2014, around 13:00_, both _Brand Tempestad_ and _Elsa Orilla_ were around the vicinity of hotel.
This is unusual because it is still office hours on a weekday and they were in a hotel.

![](img/q5_07_hote.png){width=95%}

![](img/q5_07_hotel_2.png){width=95%}


**5. Warehouse near Sannan Park**

On _January 10, 2014, 22:20_, Minke Mies visited this place. He also frequently visits the location around the _Frydos Autosupply n More_.
![](img/q5_08_warehouse_3.png){width=95%}


# 5. Conclusion

This assignment attempts to solve the 2021 VAST Challenge: Mini-Challenge 2 by applying different visual analytics concepts, methods, and techniques.


The interactive bar chart was used to identity the most popular locations which is Katerina's Cafe while interactive heatmap was used to determine the day and time when GAStech employees visit the place. 
The interactive boxplot was used to perform initial analysis of outliers while _plot_anomaly_diagnostics_ function was used to diagnose unusual purchases particularly the _10,000_ transaction in _Frydos Autosupply n More_. 


Interactive heatmap was also used to assess the anomalies where it shows the transactions with the missing credit card and loyalty card data.
Adding the gps and car data and plotting the movement path using _tmap_, 4 employees were identified who may be involved in the suspicious transactions in _Frydos Autosupply n More_.


An approach was proposed to determine the owners of the loyalty and credit card data. 
It involves mapping the credit card transaction purchases timestamp against the interactive 'Point of Interest' map.


Similar to POI, relationship among the GASTech personnel was establish based on their 'close contact' with each other where they are meeting at the same place and at the same time.
An interactive network graph and heatmap were used to show the GAStech personel relationships based on the number of their interactions.


Synthesizing the information from all the questions 1 to 4 and using interactive POI maps, several locations where identified to be the place where suspicious activities are happening.


Using relevant R data visualisation and data analysis packages, the previous submissions from 2014 VAST Challenge were enhanced by adding interactive features and making the visualisation reproducible.


Finally, this assignment can still be further improved by using RShiny App and have a more friendly user interface to perform the investigation.


# 6. References

* [ISSS608 Assignment Instructions](https://isss608.netlify.app/assignment.html)

* [VAST Challenge 2021: Mini-Challenge 2](https://vast-challenge.github.io/2021/MC2.html)

* [VAST Challenge 2014: MC2 - Patterns of Life Analysis Benchmark Repository](http://visualdata.wustl.edu/varepository/VAST%20Challenge%202014/challenges/MC2%20-%20Patterns%20of%20Life%20Analysis/)

* Whiting, Mark & Cook, Kristin & Grinstein, Georges & Liggett, Kristen & Cooper, Michael & Fallon, John & Morin, Marc. (2014). [VAST challenge 2014: The Kronos incident](http://vis.cs.ucdavis.edu/vis2014papers/VIS_Conference/vast/challenge/whiting.pdf)
